{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranjalkamboj/Fine-tuning-Lora-Qlora/blob/main/Qlora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate peft bitsandbytes transformers trl\n"
      ],
      "metadata": {
        "id": "n85EbHJ6f8Hz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer\n"
      ],
      "metadata": {
        "id": "rDNupjryiIhG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /root/.cache/huggingface/datasets"
      ],
      "metadata": {
        "id": "zYy77F_Mxdc7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"tatsu-lab/alpaca\", )\n",
        "dataset = dataset['train'].shuffle(seed=42).select(range(1000))\n",
        "print(dataset[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv0KjOgXlxrY",
        "outputId": "05cf46d3-5433-4310-87fe-3194e038d5a3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'What would be the best type of exercise for a person who has arthritis?', 'input': '', 'output': 'For someone with arthritis, the best type of exercise would be low-impact activities like yoga, swimming, or walking. These exercises provide the benefits of exercise without exacerbating the symptoms of arthritis.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat would be the best type of exercise for a person who has arthritis?\\n\\n### Response:\\nFor someone with arthritis, the best type of exercise would be low-impact activities like yoga, swimming, or walking. These exercises provide the benefits of exercise without exacerbating the symptoms of arthritis.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_llama2_format(example):\n",
        "    system_prompt = \"You are a helpful assistant.\"\n",
        "\n",
        "    instruction = example['instruction'].strip()\n",
        "    input_text = example['input'].strip()\n",
        "    output_text = example['output'].strip()\n",
        "\n",
        "    if input_text == \"\":\n",
        "        full_instruction = instruction\n",
        "    else:\n",
        "        full_instruction = f\"{instruction}\\n{input_text}\"\n",
        "\n",
        "    formatted_prompt = f\"<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{full_instruction} [/INST] {output_text}</s>\"\n",
        "\n",
        "    return {\"text\": formatted_prompt}\n",
        "\n",
        "# Apply the formatting\n",
        "formatted_dataset = dataset.map(convert_to_llama2_format)\n",
        "print(formatted_dataset[0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtxd-jbltlYE",
        "outputId": "2c1f48a2-eec2-4c6a-a880-0810c4830a4d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] <<SYS>>\n",
            "You are a helpful assistant.\n",
            "<</SYS>>\n",
            "\n",
            "What would be the best type of exercise for a person who has arthritis? [/INST] For someone with arthritis, the best type of exercise would be low-impact activities like yoga, swimming, or walking. These exercises provide the benefits of exercise without exacerbating the symptoms of arthritis.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## LOra Congig paarameters\n",
        "lora_dropout=0.1\n",
        "lora_alpha=16\n",
        "lora_r=64"
      ],
      "metadata": {
        "id": "rlcvJXD96TDv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## bitsandbytes parameters\n",
        "use_4bits=True\n",
        "bnb_4bit_compute_dtype=torch.float16\n",
        "bnb_4bit_use_double_quant=True\n",
        "bnb_4bit_quant_type=\"nf4\"\n",
        "usenested_quant=False\n"
      ],
      "metadata": {
        "id": "SGAWXOwb64O5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Training parameters\n",
        "output_dir=\"./results\"\n",
        "num_train_epochs=1\n",
        "per_device_train_batch_size=4\n",
        "fp16=False\n",
        "bf16=False\n",
        "per_device_eval_batch_size=4\n",
        "gradient_accumulation_steps=1\n",
        "gradient_checkpointing=True\n",
        "max_grad_norm=0.3\n",
        "learning_rate=2e-4\n",
        "weight_decay=0.001\n",
        "optim=\"paged_adamw_32bit\"\n",
        "lr_scheduler_type=\"cosine\"\n",
        "warmup_ratio=0.03\n",
        "group_by_length=True\n",
        "save_steps=0\n",
        "logging_steps=25\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "QQGn6Ga77ZVf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}